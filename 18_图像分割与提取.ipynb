{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入所需模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "在图像处理的过程中，经常需要从图像中将前景对象作为目标图像分割或者提取出来。例如，在视频监控中，观测到的是固定背景下的视频内容，而我们对背景本身并无兴趣，感兴趣的是背景中出现的车辆、行人或者其他对象。我们希望将这些对象从视频中提取出来，而忽略那些没有对象进入背景的视频内容。\n",
    "# 用分水岭算法实现图像分割与提取\n",
    "图像分割是图像处理过程中一种非常重要的操作。分水岭算法将图像形象地比喻为地理学上的地形表面，实现图像分割，该算法非常有效。\n",
    "\n",
    "## 算法原理\n",
    "冈萨雷斯在《数字图像处理》一书中，对分水岭算法进行了细致的分析与介绍。OpenCV的官网建议学习者阅读国立巴黎高等矿业学校图像处理实验室（TheImage Processing Laboratory of MINES ParisTech）的CMM（Centre forMathematical Morphology）网站上关于分水岭算法的介绍和动画演示。\n",
    "\n",
    "任何一幅灰度图像，都可以被看作是地理学上的地形表面，灰度值高的区域可以被看成是山峰，灰度值低的区域可以被看成是山谷\n",
    "\n",
    "如果我们向每一个山谷中“灌注”不同颜色的水（这里采用了OpenCV官网的表述，冈萨雷斯将灌注表述为在山谷中打洞，然后让水穿过洞以均匀的速率上升）。那么，随着水位不断地升高，不同山谷的水就会汇集到一起。在这个过程中，为了防止不同山谷的水交汇，我们需要在水流可能汇合的地方构建堤坝。该过程将图像分成两个不同的集合：集水盆地和分水岭线。我们构建的堤坝就是分水岭线，也即对原始图像的分割。这就是分水岭算法。\n",
    "\n",
    "由于噪声等因素的影响，采用上述基础分水岭算法经常会得到过度分割的结果。过度分割会将图像划分为一个个稠密的独立小块，让分割失去了意义。\n",
    "\n",
    "为了改善图像分割效果，人们提出了基于掩模的改进的分水岭算法。改进的分水岭算法允许用户将他认为是同一个分割区域的部分标注出来（被标注的部分就称为掩模）。这样，分水岭算法在处理时，就会将标注的部分处理为同一个分割区域。大家可以尝试使用微软PowerPoint中的“删除背景”功能，加深对此改进算法的理解。\n",
    "\n",
    "## 相关函数介绍\n",
    "在OpenCV中，可以使用函数`cv2.watershed()`实现分水岭算法。在具体的实现过程中，还需要借助于形态学函数、距离变换函数`cv2.distanceTransform()`、`cv2.connectedComponents()`来完成图像分割。\n",
    "\n",
    "### 形态学函数回顾\n",
    "#### 开运算\n",
    "开运算是先腐蚀、后膨胀的操作，开运算能够去除图像内的噪声。\n",
    "\n",
    "#### 获取图像边界\n",
    "通过形态学操作和减法运算能够获取图像的边界。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=cv2.imread(\"./images/rice.png\",cv2.IMREAD_UNCHANGED)\n",
    "k=np.ones((5,5),np.uint8)\n",
    "e=cv2.erode(o,k)\n",
    "b=cv2.subtract(o,e)\n",
    "plt.subplot(131)\n",
    "plt.imshow(o)\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(e)\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(b)\n",
    "plt.axis('off') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 距离变换函数distanceTransform\n",
    "当图像内的各个子图没有连接时，可以直接使用形态学的腐蚀操作确定前景对象，但是如果图像内的子图连接在一起时，就很难确定前景对象了。此时，借助于距离变换函数`cv2.distanceTransform()`可以方便地将前景对象提取出来。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/water_coins.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "ishow=img.copy()\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, fore = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "plt.subplot(131)\n",
    "plt.imshow(ishow)\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(dist_transform)\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(fore)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 确定未知区域\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/water_coins.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "ishow=img.copy()\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "dist = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, fore = cv2.threshold(dist,0.7*dist.max(),255,0)\n",
    "fore = np.uint8(fore)\n",
    "un = cv2.subtract(bg,fore)\n",
    "plt.subplot(221)\n",
    "plt.imshow(ishow)\n",
    "plt.axis('off')\n",
    "plt.subplot(222)\n",
    "plt.imshow(bg)\n",
    "plt.axis('off')\n",
    "plt.subplot(223)\n",
    "plt.imshow(fore)\n",
    "plt.axis('off')\n",
    "plt.subplot(224)\n",
    "plt.imshow(un)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数connectedComponents\n",
    "明确了确定前景后，就可以对确定前景图像进行标注了。在OpenCV中，可以使用函数`cv2.connectedComponents()`进行标注。该函数会将背景标注为0，将其他的对象使用从1开始的正整数标注。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/water_coins.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "ishow=img.copy()\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, fore = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "fore = np.uint8(fore)\n",
    "ret, markers = cv2.connectedComponents(fore)\n",
    "plt.subplot(131)\n",
    "plt.imshow(ishow)\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(fore)\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(markers)\n",
    "plt.axis('off')\n",
    "print(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/water_coins.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "ishow=img.copy()\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, fore = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "fore = np.uint8(fore)\n",
    "ret, markers1 = cv2.connectedComponents(fore)\n",
    "foreAdv=fore.copy()\n",
    "unknown = cv2.subtract(sure_bg,foreAdv)\n",
    "ret, markers2 = cv2.connectedComponents(foreAdv)\n",
    "markers2 = markers2+1\n",
    "markers2[unknown==255] = 0\n",
    "plt.subplot(121)\n",
    "plt.imshow(markers1)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(markers2)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数`cv2.watershed()`\n",
    "完成上述处理后，就可以使用分水岭算法对预处理结果图像进行分割了。在OpenCV中，实现分水岭算法的函数是`cv2.watershed()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分水岭算法图像分割实例\n",
    "使用分水岭算法进行图像分割时，基本的步骤为：\n",
    "1. 通过形态学开运算对原始图像O去噪。\n",
    "2. 通过腐蚀操作获取“确定背景B”。需要注意，这里得到“原始图像-确定背景”即可。\n",
    "3. 利用距离变换函数`cv2.distanceTransform()`对原始图像进行运算，并对其进行阈值处理，得到“确定前景F”。\n",
    "4. 计算未知区域UN（UN=O -B - F）。\n",
    "5. 利用函数`cv2.connectedComponents()`对原始图像O进行标注。\n",
    "6. 对函数`cv2.connectedComponents()`的标注结果进行修正。\n",
    "7. 使用分水岭函数完成对图像的分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/water_coins.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "ishow=img.copy()\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "markers = markers+1\n",
    "markers[unknown==255] = 0\n",
    "markers = cv2.watershed(img,markers)\n",
    "img[markers == -1] = [0,255,0]\n",
    "plt.subplot(121)\n",
    "plt.imshow(ishow)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 交互式前景提取\n",
    "经典的前景提取技术主要使用纹理（颜色）信息，如魔术棒工具，或根据边缘（对比度）信息，如智能剪刀等完成。2004年，微软研究院（剑桥）的Rother等人在论文GrabCut: Interactive Foreground Extraction Using Iterated Graph Cuts中提出了交互式前景提取技术。他们提出的算法，仅需要做很少的交互操作，就能够准确地提取出前景图像。\n",
    "\n",
    "GrabCut算法的具体实施过程。\n",
    "1. 将前景所在的大致位置使用矩形框标注出来。值得注意的是，此时矩形框框出的仅仅是前景的大致位置，其中既包含前景又包含背景，所以该区域实际上是未确定区域。但是，该区域以外的区域被认为是“确定背景”。\n",
    "2. 根据矩形框外部的“确定背景”数据来区分矩形框区域内的前景和背景。\n",
    "3. 用高斯混合模型（Gaussians Mixture Model, GMM）对前景和背景建模。GMM会根据用户的输入学习并创建新的像素分布。对未分类的像素（可能是背景也可能是前景），根据其与已知分类像素（前景和背景）的关系进行分类。\n",
    "4. 根据像素分布情况生成一幅图，图中的节点就是各个像素点。除了像素点之外，还有两个节点：前景节点和背景节点。所有的前景像素都和前景节点相连，所有的背景像素都和背景节点相连。每个像素连接到前景节点或背景节点的边的权重由像素是前景或背景的概率来决定。\n",
    "5. 图中的每个像素除了与前景节点或背景节点相连外，彼此之间还存在着连接。两个像素连接的边的权重值由它们的相似性决定，两个像素的颜色越接近，边的权重值越大。\n",
    "6. 完成节点连接后，需要解决的问题变成了一幅连通的图。在该图上根据各自边的权重关系进行切割，将不同的点划分为前景节点和背景节点。\n",
    "7. 不断重复上述过程，直至分类收敛为止。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = cv2.imread('./images/lenacolor.png')\n",
    "orgb=cv2.cvtColor(o,cv2.COLOR_BGR2RGB)\n",
    "mask = np.zeros(o.shape[:2],np.uint8)\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "rect = (50,50,400,400)\n",
    "cv2.grabCut(o,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "ogc = o*mask2[:,:,np.newaxis]\n",
    "ogc=cv2.cvtColor(ogc,cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(121)\n",
    "plt.imshow(orgb)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(ogc)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o= cv2.imread('./images/lenacolor.png')\n",
    "orgb=cv2.cvtColor(o,cv2.COLOR_BGR2RGB)\n",
    "mask = np.zeros(o.shape[:2],np.uint8)\n",
    "bgd = np.zeros((1,65),np.float64)\n",
    "fgd = np.zeros((1,65),np.float64)\n",
    "rect = (50,50,400,500)\n",
    "cv2.grabCut(o,mask,rect,bgd,fgd,5,cv2.GC_INIT_WITH_RECT)\n",
    "mask2 = cv2.imread('./images/mask.png',0)\n",
    "mask2Show = cv2.imread('./images/mask.png',-1)\n",
    "m2rgb=cv2.cvtColor(mask2Show,cv2.COLOR_BGR2RGB)\n",
    "mask[mask2 == 0] = 0\n",
    "mask[mask2 == 255] = 1\n",
    "mask, bgd, fgd = cv2.grabCut(o,mask,None,bgd,fgd,5,cv2.GC_INIT_WITH_MASK)\n",
    "mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "ogc = o*mask[:,:,np.newaxis]\n",
    "ogc=cv2.cvtColor(ogc,cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(121)\n",
    "plt.imshow(m2rgb)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(ogc)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o= cv2.imread('./images/lenacolor.png')\n",
    "orgb=cv2.cvtColor(o,cv2.COLOR_BGR2RGB)\n",
    "bgd = np.zeros((1,65),np.float64)\n",
    "fgd = np.zeros((1,65),np.float64)\n",
    "mask2 = np.zeros(o.shape[:2],np.uint8)\n",
    "mask2[30:512,50:400]=3\n",
    "mask2[50:300,150:200]=1\n",
    "cv2.grabCut(o,mask2,None,bgd,fgd,5,cv2.GC_INIT_WITH_MASK)\n",
    "mask2 = np.where((mask2==2)|(mask2==0),0,1).astype('uint8')\n",
    "ogc = o*mask2[:,:,np.newaxis]\n",
    "ogc=cv2.cvtColor(ogc,cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(121)\n",
    "plt.imshow(orgb)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(ogc)\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b636742cd7447c915110da4af08d48b478a44c23413a0d42f0e6f825f6094b71"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('taocv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
